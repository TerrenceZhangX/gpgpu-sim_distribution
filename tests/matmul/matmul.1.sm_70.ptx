







.version 7.8
.target sm_70
.address_size 64



.visible .entry _Z9matrixMulPKiS0_Pii(
.param .u64 _Z9matrixMulPKiS0_Pii_param_0,
.param .u64 _Z9matrixMulPKiS0_Pii_param_1,
.param .u64 _Z9matrixMulPKiS0_Pii_param_2,
.param .u32 _Z9matrixMulPKiS0_Pii_param_3
)
{
.reg .pred %p<6>;
.reg .b32 %r<54>;
.reg .b64 %rd<35>;


ld.param.u64 %rd18, [_Z9matrixMulPKiS0_Pii_param_0];
ld.param.u64 %rd19, [_Z9matrixMulPKiS0_Pii_param_1];
ld.param.u64 %rd20, [_Z9matrixMulPKiS0_Pii_param_2];
ld.param.u32 %r17, [_Z9matrixMulPKiS0_Pii_param_3];
cvta.to.global.u64 %rd1, %rd19;
cvta.to.global.u64 %rd2, %rd18;
mov.u32 %r18, %ntid.y;
mov.u32 %r19, %ctaid.y;
mov.u32 %r20, %tid.y;
mad.lo.s32 %r21, %r19, %r18, %r20;
mov.u32 %r22, %ntid.x;
mov.u32 %r23, %ctaid.x;
mov.u32 %r24, %tid.x;
mad.lo.s32 %r1, %r23, %r22, %r24;
mul.lo.s32 %r2, %r21, %r17;
add.s32 %r25, %r2, %r1;
cvta.to.global.u64 %rd21, %rd20;
mul.wide.s32 %rd22, %r25, 4;
add.s64 %rd3, %rd21, %rd22;
mov.u32 %r50, 0;
st.global.u32 [%rd3], %r50;
setp.lt.s32 %p1, %r17, 1;
@%p1 bra $L__BB0_7;

add.s32 %r29, %r17, -1;
and.b32 %r53, %r17, 3;
setp.lt.u32 %p2, %r29, 3;
mov.u32 %r51, %r50;
@%p2 bra $L__BB0_4;

sub.s32 %r49, %r17, %r53;
mul.wide.s32 %rd23, %r1, 4;
add.s64 %rd32, %rd1, %rd23;
mul.wide.s32 %rd24, %r2, 4;
add.s64 %rd25, %rd2, %rd24;
add.s64 %rd31, %rd25, 8;
mul.wide.s32 %rd6, %r17, 4;
mov.u32 %r50, 0;
mov.u32 %r51, %r50;

$L__BB0_3:
ld.global.u32 %r32, [%rd32];
ld.global.u32 %r33, [%rd31+-8];
mad.lo.s32 %r34, %r32, %r33, %r50;
st.global.u32 [%rd3], %r34;
add.s64 %rd26, %rd32, %rd6;
ld.global.u32 %r35, [%rd26];
ld.global.u32 %r36, [%rd31+-4];
mad.lo.s32 %r37, %r35, %r36, %r34;
st.global.u32 [%rd3], %r37;
add.s64 %rd27, %rd26, %rd6;
ld.global.u32 %r38, [%rd27];
ld.global.u32 %r39, [%rd31];
mad.lo.s32 %r40, %r38, %r39, %r37;
st.global.u32 [%rd3], %r40;
add.s64 %rd28, %rd27, %rd6;
add.s64 %rd32, %rd28, %rd6;
ld.global.u32 %r41, [%rd28];
ld.global.u32 %r42, [%rd31+4];
mad.lo.s32 %r50, %r41, %r42, %r40;
st.global.u32 [%rd3], %r50;
add.s32 %r51, %r51, 4;
add.s64 %rd31, %rd31, 16;
add.s32 %r49, %r49, -4;
setp.ne.s32 %p3, %r49, 0;
@%p3 bra $L__BB0_3;

$L__BB0_4:
setp.eq.s32 %p4, %r53, 0;
@%p4 bra $L__BB0_7;

mad.lo.s32 %r43, %r51, %r17, %r1;
mul.wide.s32 %rd29, %r43, 4;
add.s64 %rd34, %rd1, %rd29;
mul.wide.s32 %rd12, %r17, 4;
add.s32 %r44, %r51, %r2;
mul.wide.s32 %rd30, %r44, 4;
add.s64 %rd33, %rd2, %rd30;

$L__BB0_6:
.pragma "nounroll";
ld.global.u32 %r45, [%rd34];
ld.global.u32 %r46, [%rd33];
mad.lo.s32 %r50, %r45, %r46, %r50;
st.global.u32 [%rd3], %r50;
add.s64 %rd34, %rd34, %rd12;
add.s64 %rd33, %rd33, 4;
add.s32 %r53, %r53, -1;
setp.ne.s32 %p5, %r53, 0;
@%p5 bra $L__BB0_6;

$L__BB0_7:
ret;

}

